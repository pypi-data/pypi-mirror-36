{"description_content_type": "text/markdown", "extensions": {"python.details": {"contacts": [{"email": "ashley.hill@u-psud.fr", "name": "Ashley Hill", "role": "author"}], "document_names": {"description": "DESCRIPTION.rst", "license": "LICENSE.txt"}, "project_urls": {"Home": "https://github.com/hill-a/stable-baselines"}}}, "extras": [], "generator": "bdist_wheel (0.30.0)", "keywords": ["reinforcement-learning-algorithms", "reinforcement-learning", "machine-learning", "gym", "openai", "baselines", "toolbox", "python", "data-science"], "license": "MIT", "metadata_version": "2.0", "name": "stable-baselines", "run_requires": [{"requires": ["click", "cloudpickle", "dill", "glob2", "gym[classic_control,atari,mujoco,robotics]", "joblib", "matplotlib", "mpi4py", "numpy", "opencv-python", "pandas", "progressbar2", "pytest", "scipy", "seaborn", "tensorflow (>=1.5.0)", "tqdm", "zmq"]}], "summary": "A fork of OpenAI Baselines, implementations of reinforcement learning algorithms.", "version": "2.1.0"}