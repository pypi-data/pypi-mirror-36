{"interface_hash": "fef36b872557ae10b58aa26abbd86a46", "hash": "2224158638fca1744f5e089ab598fb24", "version_id": "0.520", "child_modules": ["allennlp.data.tokenizers.word_tokenizer", "allennlp.data.tokenizers.character_tokenizer", "allennlp.data.tokenizers.word_stemmer", "allennlp.data.tokenizers.word_filter", "allennlp.data.tokenizers.word_splitter"], "path": "/home/mattg/clone/allennlp/allennlp/data/tokenizers/__init__.py", "mtime": 1500401967, "size": 142, "id": "allennlp.data.tokenizers", "dependencies": ["allennlp.data.tokenizers.word_tokenizer", "allennlp.data.tokenizers.character_tokenizer", "builtins"], "suppressed": [], "data_mtime": 1501464789, "dep_prios": [5, 5, 5], "options": {"strict_optional_whitelist": null, "quick_and_dirty": false, "strict_optional": false, "warn_no_return": true, "ignore_errors": false, "disallow_any": [], "strict_boolean": false, "warn_return_any": false, "debug_cache": false, "no_implicit_optional": false, "ignore_missing_imports": true, "follow_imports": "normal", "disallow_untyped_calls": false, "platform": "linux", "check_untyped_defs": false, "disallow_untyped_defs": false, "show_none_errors": true}}