# Stubs for pyspark.ml.util (Python 3.5)
#

from typing import Any
from pyspark.sql.context import SQLContext
from pyspark.sql.session import SparkSession

basestring = ...  # type: type
unicode = ...  # type: type

class Identifiable:
    uid = ...  # type: str
    def __init__(self) -> None: ...

class MLWriter:
    def save(self, path: str) -> None: ...
    def overwrite(self) -> MLWriter: ...
    def context(self, sqlContext: SQLContext) -> MLWriter: ...
    def session(self, sparkSession: SparkSession) -> MLWriter: ...

class JavaMLWriter(MLWriter):
    def __init__(self, instance) -> None: ...
    def save(self, path: str) -> None: ...
    def overwrite(self) -> JavaMLWriter: ...
    def context(self, sqlContext: SQLContext) -> JavaMLWriter: ...
    def session(self, sparkSession: SparkSession) -> JavaMLWriter: ...

class MLWritable:
    def write(self) -> MLWriter: ...
    def save(self, path: str) -> None: ...

class JavaMLWritable(MLWritable):
    def write(self) -> JavaMLWriter: ...

class MLReader:
    def load(self, path: str) -> Any: ...
    def context(self, sqlContext: SQLContext) -> MLReader: ...
    def session(self, sparkSession: SparkSession) -> MLReader: ...

class JavaMLReader(MLReader):
    def __init__(self, clazz: type) -> None: ...
    def load(self, path: str) -> Any: ...
    def context(self, sqlContext: SQLContext) -> JavaMLReader: ...
    def session(self, sparkSession: SparkSession) -> JavaMLReader: ...

class MLReadable:
    @classmethod
    def read(cls) -> MLReader: ...
    @classmethod
    def load(cls, path: str) -> MLReadable: ...

class JavaMLReadable(MLReadable):
    @classmethod
    def read(cls) ->  JavaMLReader: ...

class JavaPredictionModel:
    @property
    def numFeatures(self) -> int: ...
