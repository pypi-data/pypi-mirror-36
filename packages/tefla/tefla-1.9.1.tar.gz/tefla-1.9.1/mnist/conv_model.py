from tefla.core.layer_arg_ops import common_layer_args, make_args, end_points
from tefla.core.layers import conv2d, fully_connected, max_pool, softmax, prelu, dropout

width = 28
height = 28


def model(x, is_training, reuse, num_classes=10):
  common_args = common_layer_args(is_training, reuse)
  conv_args = make_args(batch_norm=True, activation=prelu, **common_args)
  fc_args = make_args(activation=prelu, **common_args)
  logit_args = make_args(activation=None, **common_args)

  x = conv2d(x, 32, name='conv1_1', **conv_args)
  x = conv2d(x, 32, name='conv1_2', **conv_args)
  x = max_pool(x, name='pool1', **common_args)
  x = dropout(x, drop_p=0.25, name='dropout1', **common_args)
  x = fully_connected(x, n_output=128, name='fc1', **fc_args)
  x = dropout(x, drop_p=0.5, name='dropout2', **common_args)
  logits = fully_connected(x, n_output=num_classes, name="logits", **logit_args)
  predictions = softmax(logits, name='predictions', **common_args)

  return end_points(is_training)
