# -*- coding: utf-8 -*-
from __future__ import unicode_literals

import re


class _LinearCongruentialGenerator(object):

    _modulus = 4294967296
    _multiplier = 1664525
    _increment = 1013904223

    def __init__(self, seed):
        self._value = seed % self._modulus

    def get(self):
        self._value = (((self._multiplier * self._value) + self._increment) %
                       self._modulus)
        return self._value


_letter_map = {
    'a': ['ร', 'รก', 'รข', 'รฃ', 'รค', 'รฅ', 'ฤ', 'ฤ', 'ฤ', 'ว', 'ว', 'วก', 'วป', 'ศ',
          'ศ', 'ศง', 'ำ', 'ำ', 'แถ', 'แธ', 'แบ', 'แบก', 'แบฃ', 'แบฅ', 'แบง', 'แบฉ', 'แบซ', 'แบญ',
          'แบฏ', 'แบฑ', 'แบณ', 'แบต', 'แบท', 'ษ', 'ฮฑ', 'ฮฌ', 'แผ', 'แผ', 'แผ', 'แผ', 'แผ',
          'แผ', 'แผ', 'แผ', 'แฝฐ', 'แฝฑ'],
    'b': ['ฦ', 'ฦ', 'ษ', 'แตฌ', 'แถ', 'แธ', 'แธ', 'แธ'],
    'c': ['รง', 'ฤ', 'ฤ', 'ฤ', 'ฤ', 'ฦ', 'ศผ', 'ษ', 'แธ', 'ยข'],
    'd': ['ฤ', 'ฤ', 'ฦ', 'ศก', 'ษ', 'ษ', 'แตญ', 'แถ', 'แถ', 'แธ', 'แธ', 'แธ', 'แธ',
          'แธ'],
    'e': ['รจ', 'รฉ', 'รช', 'รซ', 'ฤ', 'ฤ', 'ฤ', 'ฤ', 'ฤ', 'ศ', 'ศ', 'ศฉ', 'แถ', 'แธ',
          'แธ', 'แธ', 'แธ', 'แธ', 'แบน', 'แบป', 'แบฝ', 'แบฟ', 'แป', 'แป', 'แป', 'แป', 'ว'],
    'f': ['ฦ', 'แตฎ', 'แถ', 'แธ', 'ฦ'],
    'g': ['ฤ', 'ฤ', 'ฤก', 'ฤฃ', 'วฅ', 'วง', 'วต', 'ษ', 'แถ', 'แธก', 'แตท'],
    'h': ['ฤฅ', 'ฤง', 'ศ', 'ษฆ', 'แธฃ', 'แธฅ', 'แธง', 'แธฉ', 'แธซ', 'แบ'],
    'i': ['รฌ', 'รญ', 'รฎ', 'รฏ', 'ฤฉ', 'ฤซ', 'ฤญ', 'ฤฏ', 'ว', 'ศ', 'ศ', 'ษจ', 'แถ', 'แธญ',
          'แธฏ', 'แป', 'แป'],
    'j': ['ฤต', 'วฐ', 'ส'],
    'k': ['ฤท', 'ฦ', 'วฉ', 'แถ', 'แธฑ', 'แธณ', 'แธต', 'ส'],
    'l': ['ฤบ', 'ฤผ', 'ฤพ', 'ล', 'ล', 'ฦ', 'ศด', 'ษซ', 'ษฌ', 'ษญ', 'แถ', 'แธท', 'แธน', 'แธป',
          'แธฝ', 'โ'],
    'm': ['ษฑ', 'แตฏ', 'แถ', 'แธฟ', 'แน', 'แน'],
    'n': ['รฑ', 'ล', 'ล', 'ล', 'ฦ', 'วน', 'ศต', 'ษฒ', 'ษณ', 'แตฐ', 'แถ', 'แน', 'แน', 'แน',
          'แน', 'ฮท', 'ฮฎ', 'แผ', 'แผก', 'แผข', 'แผฃ', 'แผค', 'แผฅ', 'แผฆ', 'แผง', 'แฝด', 'แฝต'],
    'o': ['รฒ', 'รณ', 'รด', 'รต', 'รถ', 'รธ', 'ล', 'ล', 'ล', 'ฦก', 'ว', 'วซ', 'วญ', 'วฟ',
          'ศ', 'ศ', 'ศซ', 'ศญ', 'ศฏ', 'ศฑ', 'ำง', 'แน', 'แน', 'แน', 'แน', 'แป', 'แป', 'แป',
          'แป', 'แป', 'แป', 'แป', 'แป', 'แป', 'แป', 'แปก', 'แปฃ'],
    'p': ['ฦฅ', 'แตฑ', 'แตฝ', 'แถ', 'แน', 'แน'],
    'q': ['ส'],
    'r': ['ล', 'ล', 'ล', 'ศ', 'ศ', 'ษผ', 'ษฝ', 'ษพ', 'แตฒ', 'แตณ', 'แถ', 'แน', 'แน', 'แน',
          'แน'],
    's': ['ล', 'ล', 'ล', 'ลก', 'ศ', 'ศฟ', 'ส', 'แตด', 'แถ', 'แนก', 'แนฃ', 'แนฅ', 'แนง',
          'แนฉ'],
    't': ['ลฃ', 'ลฅ', 'ลง', 'ฦซ', 'ฦญ', 'ศ', 'ศถ', 'ส', 'แตต', 'แนซ', 'แนญ', 'แนฏ', 'แนฑ',
          'แบ', 'โ'],
    'u': ['รน', 'รบ', 'รป', 'รผ', 'ลฉ', 'ลซ', 'ลญ', 'ลฏ', 'ลฑ', 'ลณ', 'ฦฐ', 'ว', 'ว', 'ว',
          'ว', 'ว', 'ศ', 'ศ', 'แถ', 'แนณ', 'แนต', 'แนท', 'แนน', 'แนป', 'แปฅ', 'แปง', 'แปฉ', 'แปซ',
          'แปญ', 'แปฏ', 'แปฑ', 'ฮผ'],
    'v': ['ส', 'แถ', 'แนฝ', 'แนฟ'],
    'w': ['ลต', 'แบ', 'แบ', 'แบ', 'แบ', 'แบ', 'แบ', 'ฯ', 'ฯ', 'แฝ', 'แฝก', 'แฝข', 'แฝฃ',
          'แฝค', 'แฝฅ', 'แฝฆ', 'แฝง', 'แฝผ', 'แฝฝ'],
    'x': ['แถ', 'แบ', 'แบ', 'ร'],
    'y': ['รฝ', 'รฟ', 'ลท', 'ฦด', 'ศณ', 'แบ', 'แบ', 'แปณ', 'แปต', 'แปท', 'แปน', 'ำฎ', 'ำฐ',
          'ำฒ', 'ฮณ'],
    'z': ['ลบ', 'ลผ', 'ลพ', 'ฦถ', 'ศฅ', 'ษ', 'ส', 'ส', 'แตถ', 'แถ', 'แบ', 'แบ', 'แบ'],
    'A': ['ร', 'ร', 'ร', 'ร', 'ร', 'ร', 'ฤ', 'ฤ', 'ฤ', 'ว', 'ว', 'ว', 'วบ', 'ศ',
          'ศ', 'ศฆ', 'ศบ', 'ำ', 'ำ', 'แธ', 'แบ', 'แบข', 'แบค', 'แบฆ', 'แบจ', 'แบช', 'แบฌ', 'แบฎ',
          'แบฐ', 'แบฒ', 'แบด', 'แบถ', 'ฮ', '๐ธ'],
    'B': ['ฦ', 'แธ', 'แธ', 'แธ', 'ฮฒ', 'ร', '๐น'],
    'C': ['ร', 'ฤ', 'ฤ', 'ฤ', 'ฤ', 'ฦ', 'ศป', 'แธ', 'โญ', 'โ'],
    'D': ['ฤ', 'ฤ', 'ฦ', 'ฦ', 'แธ', 'แธ', 'แธ', 'แธ', 'แธ', '๐ป'],
    'E': ['ร', 'ร', 'ร', 'ร', 'ฤ', 'ฤ', 'ฤ', 'ฤ', 'ฤ', 'ศ', 'ศ', 'ศจ', 'แธ', 'แธ',
          'แธ', 'แธ', 'แธ', 'แบธ', 'แบบ', 'แบผ', 'แบพ', 'แป', 'แป', 'แป', 'แป', 'โฌ', '๐ผ'],
    'F': ['ฦ', 'แธ', 'โฒ', '๐ฝ'],
    'G': ['ฤ', 'ฤ', 'ฤ', 'ฤข', 'ฦ', 'วค', 'วฆ', 'วด', 'แธ', 'โ', '๐พ'],
    'H': ['ฤค', 'ฤฆ', 'ศ', 'แธข', 'แธค', 'แธฆ', 'แธจ', 'แธช', 'โ', 'โ'],
    'I': ['ร', 'ร', 'ร', 'ร', 'ฤจ', 'ฤช', 'ฤฌ', 'ฤฎ', 'ฤฐ', 'ฦ', 'ว', 'ศ', 'ศ', 'แตป',
          'แธฌ', 'แธฎ', 'แป', 'แป'],
    'J': ['ฤด', '๐'],
    'K': ['ฤถ', 'ฦ', 'วจ', 'แธฐ', 'แธฒ', 'แธด', '๐'],
    'L': ['ฤน', 'ฤป', 'ฤฝ', 'ฤฟ', 'ล', 'ศฝ', 'แธถ', 'แธธ', 'แธบ', 'แธผ', '๐'],
    'M': ['แธพ', 'แน', 'แน', '๐'],
    'N': ['ร', 'ล', 'ล', 'ล', 'ฦ', 'วธ', 'ศ', 'แน', 'แน', 'แน', 'แน', 'ะ', 'ำข', 'ำค',
          'ะ', 'ะ', 'โ'],
    'O': ['ร', 'ร', 'ร', 'ร', 'ร', 'ร', 'ล', 'ล', 'ล', 'ฦ', 'ฦ', 'ว', 'วช', 'วฌ',
          'วพ', 'ศ', 'ศ', 'ศช', 'ศฌ', 'ศฎ', 'ศฐ', 'ำฆ', 'แน', 'แน', 'แน', 'แน', 'แป', 'แป',
          'แป', 'แป', 'แป', 'แป', 'แป', 'แป', 'แป', 'แป', 'แป', 'แปข', 'ฮ', '๐', 'โ'],
    'P': ['ฦค', 'แน', 'แน', 'โ'],
    'Q': ['โบ', 'โ'],
    'R': ['ล', 'ล', 'ล', 'ศ', 'ศ', 'แน', 'แน', 'แน', 'แน', 'แด', 'โ', 'โ', 'โ'],
    'S': ['ล', 'ล', 'ล', 'ล', 'ศ', 'แน', 'แนข', 'แนค', 'แนฆ', 'แนจ', '๐'],
    'T': ['ลข', 'ลค', 'ลฆ', 'ฦฌ', 'ฦฎ', 'ศ', 'ศพ', 'แนช', 'แนฌ', 'แนฎ', 'แนฐ', '๐'],
    'U': ['ร', 'ร', 'ร', 'ร', 'ลจ', 'ลช', 'ลฌ', 'ลฎ', 'ลฐ', 'ลฒ', 'ฦฏ', 'ว', 'ว', 'ว',
          'ว', 'ว', 'ศ', 'ศ', 'แตพ', 'แนฒ', 'แนด', 'แนถ', 'แนธ', 'แนบ', 'แปค', 'แปฆ', 'แปจ', 'แปช',
          'แปฌ', 'แปฎ', 'แปฐ', '๐'],
    'V': ['ฦฒ', 'แนผ', 'แนพ', '๐', 'โฃ'],
    'W': ['ลด', 'แบ', 'แบ', 'แบ', 'แบ', 'แบ', '๐'],
    'X': ['แบ', 'แบ', '๐'],
    'Y': ['ร', 'ลถ', 'ลธ', 'ฦณ', 'ศฒ', 'แบ', 'แปฒ', 'แปด', 'แปถ', 'แปธ', 'ฮจ', '๐'],
    'Z': ['ลน', 'ลป', 'ลฝ', 'ฦต', 'ศค', 'แบ', 'แบ', 'แบ', 'โค'],
}


def _translate(text):
    random = _LinearCongruentialGenerator(sum([ord(l) for l in text]))

    result = ''
    for letter in text:
        if letter in _letter_map:
            i = random.get() % len(_letter_map[letter])
            result += _letter_map[letter][i]
        else:
            result += letter

    return result


_consonents = r'[BCDFGHJKLMNPQRSTVWXYZbcdfghjklmnpqrstvwxyz]'
_vowels = r'[AEIOUaeiou]'

_elongation_patterns = [
    re.compile(_consonents + r'(a+)' + _consonents),
    re.compile(r'(bb+)'),
    re.compile(r'c(h+)'),
    re.compile(r'(dd+)'),
    re.compile(r'(ee+)'),
    re.compile(r'(f+)'),
    re.compile(r'(gg+)'),
    re.compile(_consonents + r'(i+)' + _consonents),
    re.compile(r'(k+)'),
    re.compile(r'(ll+)'),
    re.compile(r'(m+)'),
    re.compile(_vowels + r'(n+)[dg\b]'),
    re.compile(r'(oo+)'),
    re.compile(r'(pp+)'),
    re.compile(r'(r+)'),
    re.compile(r'(s+)'),
    re.compile(r's(h+)'),
    re.compile(r'(tt+)'),
    re.compile(_consonents + r'(u+)' + _consonents),
    re.compile(r'(x+)'),
    re.compile(r'(y+)\b'),
    re.compile(r'(z+)'),
]


def _elongate(text, n):
    if n <= 0:
        return text

    orig_len = len(text)
    if 0 < n < 1:
        n = int(round(orig_len * n))

    random = _LinearCongruentialGenerator(sum([ord(l) for l in text]))

    num_patterns = len(_elongation_patterns)

    for _ in xrange(n * num_patterns):
        pattern = _elongation_patterns[random.get() % num_patterns]
        matches = list(pattern.finditer(text))
        if not matches:
            continue

        match = matches[random.get() % len(matches)]
        replacement = match.group(1) + match.group(1)[-1]
        text = text[:match.start(1)] + replacement + text[match.end(1):]

        if len(text) - orig_len >= n:
            break

    return text


_fragment_placeholder = u'\xff\x2a\x7e\x00'
_fragment_pattern = re.compile(r"""
(
    # HTML tags
    <[^>]*>
    # HTML entities
    | &[^\s;]+;
    # % format
    | %(?:\([^\)]+\))?s
    # escaped { for format string
    | \{\{
    # escaped } for format string
    | \}\}
    # {} format specifier
    | \{(?:[^\{\}]|\{[^\{\}]*\})*\}
)
""", re.VERBOSE)


def _extract_fragments(text):
    matches = list(_fragment_pattern.finditer(text))
    if not matches:
        return text, []

    fragments = []
    result = ''
    pos = 0
    for match in matches:
        fragments.append(text[match.start(1):match.end(1)])
        result += text[pos:match.start(1)] + _fragment_placeholder
        pos = match.end(1)

    result += text[pos:]

    return result, fragments


def _restore_fragments(text, fragments):
    pl = len(_fragment_placeholder)

    for fragment in fragments:
        i = text.index(_fragment_placeholder)
        text = text[:i] + fragment + text[i + pl:]

    return text


def deasciiify(text, elongate=0):
    """Translate ASCII text into readable non-ASCII text

    >>> # basic usage
    >>> print(deasciiify('The quick brown fox jumps over the lazy dog.'))
    แนฐแธฅแบน สวรฎฤส ษแนลแบแน แถรธร วฐรบแนแถศ รณสแถแน แตตฤฅฤ ศดแบกแตถรฝ แธแปแธก.

    >>> # elongate by 50%
    >>> print(deasciiify('The quick brown fox jumps over the lazy dog.',
    ...                  elongate=0.5))
    ๐ศแบน สลฏแธญฤแธฑ แตฌแนแปแบรฑ แธแธแถแตฎแปฃแบแถ วฐฦฐแธฟแนแตฑแนฃแตดแนฃ วซแนฝแบฟแนแตณ แนญฤงศ ษซรควฤแบฉลพษแบแบแบแถแถแบแบแปนรฟลทำฎ แธรถแตท.

    >>> # elongate by 100 characters
    >>> print(deasciiify('The quick brown fox jumps over the lazy dog.',
    ...                  elongate=100))
    ... # doctest: +NORMALIZE_WHITESPACE
    ฦฎษฆแบป สลฑศแธฦแธฑแถแธตแธณฤทสวฉฦแธฑแถแธตแธณ ฦแถลแบแผฆ ฦแธแธแถแธฦแปแถรแบแบแถ ฤตแปฉศแปญววแนทศวรปแปงลฉแนณแนนแปฏแปฅแนปฦฐแนษฑแธฟแนแธฟษฑแธฟแนแถลแตดศลศ
    ศซแนฝแธษฝแตณษพลลลศแนษผแตณศแตณษฝศศแถแตณแถ ฦญแบฤ โแผแบญแบณแบฉแบงแบกแบณแผแบงวกแถแบกแถฦถลพลบฦถศฅแถแบแตถลผศฅแถแบแถฮณฦดแบำฒำฐรฝแปณลทแบฮณแบแปณ แถแปวฅ.

    >>> # preserve HTML, entities, and gettext params
    >>> print(deasciiify(
    ...     'The <em>quick</em> <strong style="color:brown;">brown</strong> '
    ...     'fox %(verb)s over the &ldquo;lazy&rdquo; %s.'))
    ... # doctest: +NORMALIZE_WHITESPACE
    แนฎศรจ <em>สรบแถฤแธต</em> <strong style="color:brown;">แธแตฒรณแบแผข</strong> แธแปแบ %(verb)s
    ศสแปล แนฑศแธ &ldquo;แธฝำลผำฎ&rdquo; %s.

    >>> # preserve Python brace format params
    >>> print(deasciiify(
    ...     'The {} brown fox {verb} over the lazy dog. '
    ...     'Escaped braces: {{escaped}}'))
    ลฆแธฉแบป {} แธแถแปฯล แธรถแถ {verb} แนแนฝฤศ ลงฤฅแป ฤบรฅสรฝ ฤรฒฤ. แธสฤแผแนแธษ แธลแผฤฤแนฅ: {{แบปศฟรงแบฉแนแธฦ}}

    """
    text, fragments = _extract_fragments(text)
    text = _translate(_elongate(text, elongate))
    text = _restore_fragments(text, fragments)
    return text


if __name__ == '__main__':
    import doctest
    doctest.testmod(verbose=True, optionflags=doctest.NORMALIZE_WHITESPACE)
